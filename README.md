# DippDiff
DippDiff: Box-Guided Multi-Factor Attention Excitation for Textile Digital Printing Pattern Generation
# Abstract
Diffusion models have demonstrated significant potential in the field of artistic creation. Text-to-image generation models can efficiently generate personalized and layout-controllable textile digital printing patterns (TDIPPs). However, text prompts alone often fail to accurately specify the layout of TDIPPs. Moreover, existing advanced layout control models exhibit unsatisfactory accuracy in layout control and object color binding, particularly when handling complex layout of TDIPPs. In this paper, we develop a novel box-guided layout control method called DippDiff for TDIPP generation, which leverages multi-factor token attention excitation to enhance spatial precision and design coherence. The proposed DippDiff utilizes the ControlNet to achieve cross-modal feature fusion. To address inaccurate layout control, we first utilize bounding box images generated from user-provided reference images as an additional control condition to guide the spatial layout of patterns. Then we enforce positive attention excitation within the boxes and negative excitation outside by introducing a cross-attention loss and a self-attention loss, aiming at achieving accurate layout control and pattern detail refinement, respectively. To address erroneous color binding, we propose a novel joint multi-factor token cross-attention excitation mechanism that encourages the model to focus more on pattern style, object color, object category, and background color. Moreover, we constructe PrintingData, the most detailed text-annotated digital printing pattern dataset, for model fine-tuning. We conduct a comprehensive performance evaluation on the PrintingData dataset through extensive comparative and ablation studies. The results demonstrate that the proposed DippDiff outperforms state-of-the-art layout control methods in terms of layout accuracy and color attribute binding, enabling the synthesis of high-quality TDIPPs with both innovation and artistic value.
# The overall framework
[Fig4.pdf](https://github.com/user-attachments/files/19939086/Fig4.pdf)
Fig. 1 The framework of our proposed DippDiff method.
# Qualitive results
[Fig7.pdf](https://github.com/user-attachments/files/19939146/Fig7.pdf)
Fig. 2 The visualization results of TDIPPs generated by our DippDiff method. 
[Fig9.pdf](https://github.com/user-attachments/files/19939157/Fig9.pdf)
Fig. 3 Qualitative comparison of our DippDiff method with various SOTA layout control approaches in the same seed. 
[Fig1.pdf](https://github.com/user-attachments/files/19939221/Fig1.pdf)
Fig. 4 Comparison with SOTA methods. Examples of TDIPPs generated by different methods for different prompts and layout.
# Quantitative results
Table 1 Quantitative comparison between our proposed DippDiff method and different SOTA methods on PrintingData. 
![Table1](https://github.com/user-attachments/assets/43080715-7f9d-47e7-bb72-d4964aee8d41)
